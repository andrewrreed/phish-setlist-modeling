{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP Model Inference\n",
    "\n",
    "The purpose of this notebook is build utlity functions for generating predictions from a pre-trained setlist model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Setlist Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load X data\n",
    "\n",
    "X_test = src.util.load_pickle_object('../data/processed/mvp-setlist-modeling/seqlen-150/X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3529, 150)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The testing data consists of ~3.5k sequences of 150 encoded songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([576,   9, 181,  57, 481,  15, 118, 325, 727, 451, 320, 817, 699,\n",
       "       272,   7, 148, 274,   8, 729,  46, 118, 855,  96, 143, 239, 745,\n",
       "       533, 194, 576,   9, 545, 733,  15, 707, 186, 624, 305, 861, 384,\n",
       "       148,  67,   7, 827,   8, 148, 733, 674, 729,  46, 545, 384, 451,\n",
       "       320, 817, 746, 727, 533,   9, 120, 571, 481,  96, 178, 686, 745,\n",
       "       855, 647, 291, 624,  15, 167,   7, 691,   8, 272, 213, 178,  96,\n",
       "       481, 551, 181, 194, 727, 576,   9, 380,  92, 733,  15, 241, 861,\n",
       "         7, 274,   8, 533, 855, 226, 807, 786, 792, 733, 674, 686, 577,\n",
       "       861, 274,   9, 256, 451, 320, 817, 369, 727, 647, 148, 384, 554,\n",
       "       124, 305, 347,   7, 120, 675, 827,   8,   7, 167,   8, 272, 861,\n",
       "       807, 686, 533, 241, 551, 181, 120,   9, 451, 320, 817, 213, 792,\n",
       "       745, 727, 325, 274,   7, 148, 305])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[576   9 181  57 481  15 118 325 727 451 320 817 699 272   7 148 274   8\n",
      " 729  46 118 855  96 143 239 745 533 194 576   9 545 733  15 707 186 624\n",
      " 305 861 384 148  67   7 827   8 148 733 674 729  46 545 384 451 320 817\n",
      " 746 727 533   9 120 571 481  96 178 686 745 855 647 291 624  15 167   7\n",
      " 691   8 272 213 178  96 481 551 181 194 727 576   9 380  92 733  15 241\n",
      " 861   7 274   8 533 855 226 807 786 792 733 674 686 577 861 274   9 256\n",
      " 451 320 817 369 727 647 148 384 554 124 305 347   7 120 675 827   8   7\n",
      " 167   8 272 861 807 686 533 241 551 181 120   9 451 320 817 213 792 745\n",
      " 727 325 274   7 148 305]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/anreed/anaconda3/envs/phish-modeling36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/anreed/anaconda3/envs/phish-modeling36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/anreed/anaconda3/envs/phish-modeling36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = load_model('../models/mvp-setlist-modeling/model.nn_arch_2-150-seqlen-100-lstmunits-0.5-b_dropout-0.5-a_dropout.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load encoding mappings\n",
    "idx_to_song = src.util.load_pickle_object('../data/processed/mvp-setlist-modeling/seqlen-150/idx_to_song.pkl')\n",
    "song_to_idx = src.util.load_pickle_object('../data/processed/mvp-setlist-modeling/seqlen-150/song_to_idx.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an input sequence of the last show\n",
    "test_seq = X_test[-69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([245, 126,   7, 826,   8, 108, 531, 373, 538, 121, 720, 618, 647,\n",
       "       482, 280, 624, 675,   9, 424, 167, 730, 364, 382, 364, 609, 533,\n",
       "       398,  32,   7, 256,   8, 344, 181, 843, 855, 643, 247, 282, 576,\n",
       "       291,   9, 321, 742, 541, 163, 741, 341, 710, 302, 360, 343,   4,\n",
       "       596, 202,  62, 184, 743, 414, 546,  10, 861, 369,  13, 674,   7,\n",
       "       474,   8, 787, 181, 535, 538, 619, 545, 691, 582,   9, 757, 373,\n",
       "       727,  57, 729,  46, 729, 397, 299, 746,   7, 419,   8,  96, 577,\n",
       "       690, 734, 364, 185, 432, 282, 124,   9, 247, 594, 861, 159, 861,\n",
       "       663, 643,  15, 675,   7, 292,   8, 121, 451,  13, 531, 817, 720,\n",
       "       618, 855, 657,  32, 226, 126,   9,  29, 167, 674, 792, 238, 627,\n",
       "       245, 672, 307, 576,   7,  17, 274,   8, 473, 473, 407,  96, 279,\n",
       "       545, 325, 690, 346, 647, 299,   9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Frankenstein',\n",
       " 'Chalk Dust Torture',\n",
       " '<ENCORE>',\n",
       " 'While My Guitar Gently Weeps',\n",
       " '<SET1>',\n",
       " 'Buried Alive',\n",
       " 'Poor Heart',\n",
       " 'Julius',\n",
       " 'Punch You in the Eye',\n",
       " 'Cars Trucks Buses',\n",
       " 'The Horse',\n",
       " 'Silent in the Morning',\n",
       " 'Split Open and Melt',\n",
       " 'NICU',\n",
       " 'Gumbo',\n",
       " 'Slave to the Traffic Light',\n",
       " 'Sweet Adeline',\n",
       " '<SET2>',\n",
       " 'Makisupa Policeman',\n",
       " 'David Bowie',\n",
       " 'The Mango Song',\n",
       " \"It's Ice\",\n",
       " 'Kung',\n",
       " \"It's Ice\",\n",
       " 'Shaggy Dog',\n",
       " 'Possum',\n",
       " 'Lifeboy',\n",
       " 'Amazing Grace',\n",
       " '<ENCORE>',\n",
       " 'Funky Bitch',\n",
       " '<SET1>',\n",
       " 'Icculus',\n",
       " 'Divided Sky',\n",
       " 'Wilson',\n",
       " 'Ya Mar',\n",
       " 'Sparkle',\n",
       " 'Free',\n",
       " 'Guyute',\n",
       " 'Run Like an Antelope',\n",
       " 'Harpua',\n",
       " '<SET2>',\n",
       " 'I Am the Sea',\n",
       " 'The Real Me',\n",
       " 'Quadrophenia',\n",
       " 'Cut My Hair',\n",
       " 'The Punk Meets the Godfather',\n",
       " \"I'm One\",\n",
       " 'The Dirty Jobs',\n",
       " 'Helpless Dancer',\n",
       " 'Is It In My Head?',\n",
       " \"I've Had Enough\",\n",
       " '5:15',\n",
       " 'Sea and Sand',\n",
       " 'Drowned',\n",
       " 'Bell Boy',\n",
       " 'Doctor Jimmy',\n",
       " 'The Rock',\n",
       " 'Love',\n",
       " \"Reign O'er Me\",\n",
       " '<SET3>',\n",
       " 'You Enjoy Myself',\n",
       " 'Jesus Just Left Chicago',\n",
       " 'A Day in the Life',\n",
       " 'Suzy Greenberg',\n",
       " '<ENCORE>',\n",
       " 'My Generation',\n",
       " '<SET1>',\n",
       " 'Tweezer Reprise',\n",
       " 'Divided Sky',\n",
       " 'Prince Caspian',\n",
       " 'Punch You in the Eye',\n",
       " 'Simple',\n",
       " 'Reba',\n",
       " 'Tela',\n",
       " 'Sample in a Jar',\n",
       " '<SET2>',\n",
       " 'Theme From the Bottom',\n",
       " 'Julius',\n",
       " 'The Lizards',\n",
       " 'Bathtub Gin',\n",
       " 'The Man Who Stepped Into Yesterday',\n",
       " 'Avenu Malkenu',\n",
       " 'The Man Who Stepped Into Yesterday',\n",
       " 'Life on Mars?',\n",
       " 'Hello My Baby',\n",
       " 'The Squirming Coil',\n",
       " '<ENCORE>',\n",
       " 'Loving Cup',\n",
       " '<SET1>',\n",
       " 'Bouncing Around the Room',\n",
       " 'Runaway Jim',\n",
       " 'Taste That Surrounds',\n",
       " 'The Old Home Place',\n",
       " \"It's Ice\",\n",
       " 'Dog Faced Boy',\n",
       " 'Maze',\n",
       " 'Guyute',\n",
       " 'Cavern',\n",
       " '<SET2>',\n",
       " 'Free',\n",
       " 'Scent of a Mule',\n",
       " 'You Enjoy Myself',\n",
       " 'Crossroads',\n",
       " 'You Enjoy Myself',\n",
       " 'Strange Design',\n",
       " 'Sparkle',\n",
       " 'AC/DC Bag',\n",
       " 'Sweet Adeline',\n",
       " '<ENCORE>',\n",
       " 'Harry Hood',\n",
       " '<SET1>',\n",
       " 'Cars Trucks Buses',\n",
       " \"Mike's Song\",\n",
       " 'A Day in the Life',\n",
       " 'Poor Heart',\n",
       " 'Weekapaug Groove',\n",
       " 'The Horse',\n",
       " 'Silent in the Morning',\n",
       " 'Ya Mar',\n",
       " 'Stash',\n",
       " 'Amazing Grace',\n",
       " 'Fee',\n",
       " 'Chalk Dust Torture',\n",
       " '<SET2>',\n",
       " 'Also Sprach Zarathustra',\n",
       " 'David Bowie',\n",
       " 'Suzy Greenberg',\n",
       " 'Uncle Pen',\n",
       " 'Fluffhead',\n",
       " 'Sleeping Monkey',\n",
       " 'Frankenstein',\n",
       " 'Suspicious Minds',\n",
       " 'Hold Your Head Up',\n",
       " 'Run Like an Antelope',\n",
       " '<ENCORE>',\n",
       " 'Acoustic Army',\n",
       " 'Good Times Bad Times',\n",
       " '<SET1>',\n",
       " 'My Friend',\n",
       " 'My Friend',\n",
       " 'Llama',\n",
       " 'Bouncing Around the Room',\n",
       " 'Guelah Papyrus',\n",
       " 'Reba',\n",
       " \"I Didn't Know\",\n",
       " 'Taste That Surrounds',\n",
       " 'If I Could',\n",
       " 'Split Open and Melt',\n",
       " 'Hello My Baby',\n",
       " '<SET2>']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idx_to_song[idx] for idx in test_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[245 126   7 826   8 108 531 373 538 121 720 618 647 482 280 624 675   9\n",
      "  424 167 730 364 382 364 609 533 398  32   7 256   8 344 181 843 855 643\n",
      "  247 282 576 291   9 321 742 541 163 741 341 710 302 360 343   4 596 202\n",
      "   62 184 743 414 546  10 861 369  13 674   7 474   8 787 181 535 538 619\n",
      "  545 691 582   9 757 373 727  57 729  46 729 397 299 746   7 419   8  96\n",
      "  577 690 734 364 185 432 282 124   9 247 594 861 159 861 663 643  15 675\n",
      "    7 292   8 121 451  13 531 817 720 618 855 657  32 226 126   9  29 167\n",
      "  674 792 238 627 245 672 307 576   7  17 274   8 473 473 407  96 279 545\n",
      "  325 690 346 647 299   9]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array([test_seq]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([test_seq]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Also Sprach Zarathustra'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction by feeding in a sequence of 150 encoded songs\n",
    "next_song = model.predict_classes(np.array([test_seq]))\n",
    "\n",
    "# lookup song name\n",
    "idx_to_song[next_song.item()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a setlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_setlist(model, seed_setlist, n_songs):\n",
    "    \"takes in a length 100 np array of previous songs and generates full next setlist\"\n",
    "    \n",
    "    setlist = []\n",
    "    \n",
    "    for _ in range(n_songs):\n",
    "        # truncate sequences\n",
    "        seq = pad_sequences([seed_setlist], maxlen=150, truncating='pre')[0]\n",
    "        # predict next song\n",
    "        next_song = model.predict_classes(np.array([seq])).item()\n",
    "        # un-encode the song\n",
    "        next_song_clean = idx_to_song[next_song]\n",
    "        # append to generated list\n",
    "        setlist.append(next_song_clean)\n",
    "        # update seed_setlist to re-run for the next song\n",
    "        seed_setlist = np.append(seed_setlist, next_song)\n",
    "        \n",
    "    return setlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Also Sprach Zarathustra',\n",
       " 'David Bowie',\n",
       " 'The Horse',\n",
       " 'Silent in the Morning',\n",
       " 'Reba',\n",
       " 'You Enjoy Myself',\n",
       " 'Hold Your Head Up',\n",
       " \"Cracklin' Rosie\",\n",
       " 'Hold Your Head Up',\n",
       " 'Harry Hood',\n",
       " '<ENCORE>',\n",
       " 'Bold As Love',\n",
       " '<SET1>',\n",
       " 'Runaway Jim',\n",
       " 'Foam',\n",
       " 'Bouncing Around the Room',\n",
       " 'Split Open and Melt',\n",
       " 'If I Could',\n",
       " 'Scent of a Mule',\n",
       " 'Stash',\n",
       " 'The Squirming Coil',\n",
       " '<SET2>',\n",
       " 'Also Sprach Zarathustra',\n",
       " 'David Bowie',\n",
       " 'The Horse']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_full_setlist(model, test_seq, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([245, 126,   7, 826,   8, 108, 531, 373, 538, 121, 720, 618, 647,\n",
       "       482, 280, 624, 675,   9, 424, 167, 730, 364, 382, 364, 609, 533,\n",
       "       398,  32,   7, 256,   8, 344, 181, 843, 855, 643, 247, 282, 576,\n",
       "       291,   9, 321, 742, 541, 163, 741, 341, 710, 302, 360, 343,   4,\n",
       "       596, 202,  62, 184, 743, 414, 546,  10, 861, 369,  13, 674,   7,\n",
       "       474,   8, 787, 181, 535, 538, 619, 545, 691, 582,   9, 757, 373,\n",
       "       727,  57, 729,  46, 729, 397, 299, 746,   7, 419,   8,  96, 577,\n",
       "       690, 734, 364, 185, 432, 282, 124,   9, 247, 594, 861, 159, 861,\n",
       "       663, 643,  15, 675,   7, 292,   8, 121, 451,  13, 531, 817, 720,\n",
       "       618, 855, 657,  32, 226, 126,   9,  29, 167, 674, 792, 238, 627,\n",
       "       245, 672, 307, 576,   7,  17, 274,   8, 473, 473, 407,  96, 279,\n",
       "       545, 325, 690, 346, 647, 299,   9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_setlist2(model, seed_setlist):\n",
    "    '''\n",
    "    Generate the remainder of a setlist given the previous 150 songs.\n",
    "    \n",
    "    Args:\n",
    "        model (.hdf5) - a Phish prediction tensorflow model\n",
    "        seed_setlist (ndarray) - encoded array of shape (150,)\n",
    "    \n",
    "    Returns:\n",
    "        setlist (list) - generated sequence of encoded songs to complete the show\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    setlist = []\n",
    "    setlist_start = False\n",
    "    pred_count = 0\n",
    "    \n",
    "    # generate remainder of setlist\n",
    "    while setlist_start == False:\n",
    "        # truncate sequences\n",
    "        seq = pad_sequences([seed_setlist], maxlen=150, truncating='pre')[0]\n",
    "        # predict next song\n",
    "        next_song = model.predict_classes(np.array([seq])).item()\n",
    "        # increment prediction counter\n",
    "        pred_count += 1\n",
    "        # check if a new setlist start is predicted (and its not the first song)\n",
    "        if next_song == 8 and pred_count > 1:\n",
    "            setlist_start = True\n",
    "        else:\n",
    "            # append to generated list\n",
    "            setlist.append(next_song)\n",
    "            # update seed_setlist to re-run for the next song\n",
    "            seed_setlist = np.append(seed_setlist, next_song)\n",
    "            \n",
    "            \n",
    "    return setlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Also Sprach Zarathustra',\n",
       " 'David Bowie',\n",
       " 'The Horse',\n",
       " 'Silent in the Morning',\n",
       " 'Reba',\n",
       " 'You Enjoy Myself',\n",
       " 'Hold Your Head Up',\n",
       " \"Cracklin' Rosie\",\n",
       " 'Hold Your Head Up',\n",
       " 'Harry Hood',\n",
       " '<ENCORE>',\n",
       " 'Bold As Love']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idx_to_song[idx] for idx in generate_full_setlist2(model, test_seq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Character Zero'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_mapping[129]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
       "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
       "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
       "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
       "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
       "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
       "       481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
       "       494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
       "       507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
       "       520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
       "       533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
       "       546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
       "       559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
       "       572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
       "       585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
       "       598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n",
       "       611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n",
       "       624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n",
       "       637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n",
       "       650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662,\n",
       "       663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675,\n",
       "       676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688,\n",
       "       689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701,\n",
       "       702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714,\n",
       "       715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727,\n",
       "       728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740,\n",
       "       741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753,\n",
       "       754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766,\n",
       "       767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779,\n",
       "       780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792,\n",
       "       793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805,\n",
       "       806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818,\n",
       "       819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831,\n",
       "       832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844,\n",
       "       845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857,\n",
       "       858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.fromiter(reverse_mapping.keys(), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([256, 843, 569, 124,   8, 731, 666,   3, 585, 386, 659, 126, 822,\n",
       "       529, 810,  44, 576,   9, 196, 222, 604, 790, 292, 517, 292,  10,\n",
       "       443,  45, 591, 619, 589, 401, 561, 674,   7, 727, 129,   8, 649,\n",
       "       790, 247, 833, 218, 814, 556, 256, 585,   9, 637, 642, 319, 171,\n",
       "        29,  57, 746,   7, 810,  92,   8, 861, 785,   1, 492, 210, 779,\n",
       "       607, 589,   9, 602, 443, 624, 533, 586, 807,   7, 464,   8, 708,\n",
       "       538,  83, 174, 465, 181, 659, 126,   9, 232, 451, 817, 255, 786,\n",
       "       119, 259, 591,   7, 619, 431, 382,  67, 627, 787])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the final sequence\n",
    "sequences_array[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences_array[-1][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = sequences_array[-1][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([seq]).ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(np.array([seq])).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tweezer Reprise'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_mapping[787]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_setlist(model, seed_setlist, n_songs):\n",
    "    \"takes in a length 100 np array of previous songs and generates full next setlist\"\n",
    "    \n",
    "    setlist = []\n",
    "    \n",
    "    for _ in range(n_songs):\n",
    "        # truncate sequences\n",
    "        seq = pad_sequences([seed_setlist], maxlen=100, truncating='pre')[0]\n",
    "        # predict next song\n",
    "        next_song = model.predict_classes(np.array([seq])).item()\n",
    "        # un-encode the song\n",
    "        next_song_ue = reverse_mapping[next_song]\n",
    "        # append to list\n",
    "        setlist.append(next_song_ue)\n",
    "        \n",
    "        # update seed_setlist\n",
    "        seed_setlist = np.append(seed_setlist, next_song)\n",
    "        \n",
    "    \n",
    "    return setlist\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<SET1>',\n",
       " 'The Landlady',\n",
       " 'Blaze On',\n",
       " 'Free',\n",
       " 'Breath and Burning',\n",
       " 'Sugar Shack',\n",
       " 'Things People Do',\n",
       " 'Devotion To a Dream',\n",
       " 'Sugar Shack',\n",
       " 'Lawn Boy',\n",
       " 'More',\n",
       " '<SET2>',\n",
       " 'Blaze On',\n",
       " 'Fuego',\n",
       " 'Taste',\n",
       " 'Carini',\n",
       " 'Dirt',\n",
       " 'Your Pet Cat',\n",
       " 'Harry Hood',\n",
       " '<ENCORE>',\n",
       " 'I Am the Walrus',\n",
       " '<SET1>',\n",
       " 'Sample in a Jar',\n",
       " 'The Moma Dance',\n",
       " 'Rift']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = sequences_array[-1][1:]\n",
    "\n",
    "generate_full_setlist(model, seq, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([843, 569, 124,   8, 731, 666,   3, 585, 386, 659, 126, 822, 529,\n",
       "       810,  44, 576,   9, 196, 222, 604, 790, 292, 517, 292,  10, 443,\n",
       "        45, 591, 619, 589, 401, 561, 674,   7, 727, 129,   8, 649, 790,\n",
       "       247, 833, 218, 814, 556, 256, 585,   9, 637, 642, 319, 171,  29,\n",
       "        57, 746,   7, 810,  92,   8, 861, 785,   1, 492, 210, 779, 607,\n",
       "       589,   9, 602, 443, 624, 533, 586, 807,   7, 464,   8, 708, 538,\n",
       "        83, 174, 465, 181, 659, 126,   9, 232, 451, 817, 255, 786, 119,\n",
       "       259, 591,   7, 619, 431, 382,  67, 627, 787], dtype=int32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequences([seq], maxlen=100, truncating='pre')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([843, 569, 124,   8, 731, 666,   3, 585, 386, 659, 126, 822, 529,\n",
       "       810,  44, 576,   9, 196, 222, 604, 790, 292, 517, 292,  10, 443,\n",
       "        45, 591, 619, 589, 401, 561, 674,   7, 727, 129,   8, 649, 790,\n",
       "       247, 833, 218, 814, 556, 256, 585,   9, 637, 642, 319, 171,  29,\n",
       "        57, 746,   7, 810,  92,   8, 861, 785,   1, 492, 210, 779, 607,\n",
       "       589,   9, 602, 443, 624, 533, 586, 807,   7, 464,   8, 708, 538,\n",
       "        83, 174, 465, 181, 659, 126,   9, 232, 451, 817, 255, 786, 119,\n",
       "       259, 591,   7, 619, 431, 382,  67, 627, 787])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = sequences_array[-1][1:]\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 843,  569,  124,    8,  731,  666,    3,  585,  386,  659,  126,\n",
       "        822,  529,  810,   44,  576,    9,  196,  222,  604,  790,  292,\n",
       "        517,  292,   10,  443,   45,  591,  619,  589,  401,  561,  674,\n",
       "          7,  727,  129,    8,  649,  790,  247,  833,  218,  814,  556,\n",
       "        256,  585,    9,  637,  642,  319,  171,   29,   57,  746,    7,\n",
       "        810,   92,    8,  861,  785,    1,  492,  210,  779,  607,  589,\n",
       "          9,  602,  443,  624,  533,  586,  807,    7,  464,    8,  708,\n",
       "        538,   83,  174,  465,  181,  659,  126,    9,  232,  451,  817,\n",
       "        255,  786,  119,  259,  591,    7,  619,  431,  382,   67,  627,\n",
       "        787, 4444])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(seq, 4444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phish-modeling36",
   "language": "python",
   "name": "phish-modeling36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
